# -*- coding: utf-8 -*-
"""Proyecto_Cognitive

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VWj5epthL2SiEQMTREHCXl26NeESpQ6X
"""

import sys
import cv2
import glob
import numpy as np
import pickle as cPickle
import time
import random
import scipy.cluster.vq as vq
from sklearn import svm
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from matplotlib import pyplot as plt
from IPython.display import Audio, display
!pip install PyMySQL
import pymysql
import random
from IPython.display import display, Javascript, Image
from google.colab.output import eval_js
from base64 import b64decode, b64encode

def mask(img):
  square = np.array([
                        [(300, 250), (300, 150), (550, 150), (550, 250)]
                        ])
  mask = np.zeros_like(img)
  mask = cv2.fillPoly(mask, square, 255)
  img = cv2.bitwise_and(img, mask)
  
  return img

from IPython.display import display, Javascript, Image
from google.colab.output import eval_js
from base64 import b64decode, b64encode

# JavaScript to properly create our live video stream using our webcam as input
def video_stream():
  js = Javascript('''
    var video;
    var div = null;
    var stream;
    var captureCanvas;
    var imgElement;
    var labelElement;
    
    var pendingResolve = null;
    var shutdown = false;
    
    function removeDom() {
       stream.getVideoTracks()[0].stop();
       video.remove();
       div.remove();
       video = null;
       div = null;
       stream = null;
       imgElement = null;
       captureCanvas = null;
       labelElement = null;
    }
    
    function onAnimationFrame() {
      if (!shutdown) {
        window.requestAnimationFrame(onAnimationFrame);
      }
      if (pendingResolve) {
        var result = "";
        if (!shutdown) {
          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);
          result = captureCanvas.toDataURL('image/jpeg', 0.8)
        }
        var lp = pendingResolve;
        pendingResolve = null;
        lp(result);
      }
    }
    
    async function createDom() {
      if (div !== null) {
        return stream;
      }

      div = document.createElement('div');
      div.style.border = '2px solid black';
      div.style.padding = '3px';
      div.style.width = '100%';
      div.style.maxWidth = '600px';
      document.body.appendChild(div);
      
      const modelOut = document.createElement('div');
      modelOut.innerHTML = "<span>Status:</span>";
      labelElement = document.createElement('span');
      labelElement.innerText = 'No data';
      labelElement.style.fontWeight = 'bold';
      modelOut.appendChild(labelElement);
      div.appendChild(modelOut);
           
      video = document.createElement('video');
      video.style.display = 'block';
      video.width = div.clientWidth - 6;
      video.setAttribute('playsinline', '');
      video.onclick = () => { shutdown = true; };
      stream = await navigator.mediaDevices.getUserMedia(
          {video: { facingMode: "environment"}});
      div.appendChild(video);

      imgElement = document.createElement('img');
      imgElement.style.position = 'absolute';
      imgElement.style.zIndex = 1;
      imgElement.onclick = () => { shutdown = true; };
      div.appendChild(imgElement);
      
      const instruction = document.createElement('div');
      instruction.innerHTML = 
          '<span style="color: red; font-weight: bold;">' +
          'When finished, click here or on the video to stop this demo</span>';
      div.appendChild(instruction);
      instruction.onclick = () => { shutdown = true; };
      
      video.srcObject = stream;
      await video.play();

      captureCanvas = document.createElement('canvas');
      captureCanvas.width = 800; //video.videoWidth;
      captureCanvas.height = 480; //video.videoHeight;
      window.requestAnimationFrame(onAnimationFrame);
      
      return stream;
    }
    async function stream_frame(label, imgData) {
      if (shutdown) {
        removeDom();
        shutdown = false;
        return '';
      }

      var preCreate = Date.now();
      stream = await createDom();
      
      var preShow = Date.now();
      if (label != "") {
        labelElement.innerHTML = label;
      }
            
      if (imgData != "") {
        var videoRect = video.getClientRects()[0];
        imgElement.style.top = videoRect.top + "px";
        imgElement.style.left = videoRect.left + "px";
        imgElement.style.width = videoRect.width + "px";
        imgElement.style.height = videoRect.height + "px";
        imgElement.src = imgData;
      }
      
      var preCapture = Date.now();
      var result = await new Promise(function(resolve, reject) {
        pendingResolve = resolve;
      });
      shutdown = false;
      
      return {'create': preShow - preCreate, 
              'show': preCapture - preShow, 
              'capture': Date.now() - preCapture,
              'img': result};
    }
    ''')

  display(js)
  
def video_frame(label, bbox):
  data = eval_js('stream_frame("{}", "{}")'.format(label, bbox))
  return data

def js_to_image(js_reply):
  """
  Params:
          js_reply: JavaScript object containing image from webcam
  Returns:
          img: OpenCV BGR image
  """
  # decode base64 image
  image_bytes = b64decode(js_reply.split(',')[1])
  # convert bytes to numpy array
  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)
  # decode numpy array into OpenCV BGR image
  img = cv2.imdecode(jpg_as_np, flags=1)

  return img

def obtencion_data_incidencias():
  latitud = round(random.randint(-90, 90), 2)
  longitud = round(random.randint(-180, 180), 2)
  hora = str(random.randint(1,24))
  minuto1 = str(random.randint(1,5))
  minuto2 = str(random.randint(0,9))
  hora_infraccion = hora + ':' + minuto1 + minuto2
  return latitud, longitud, hora_infraccion

def prediction (img, CB, k):
  detector = cv2.xfeatures2d.SIFT_create()
  descriptor = cv2.xfeatures2d.SIFT_create()

  K=[]
  D=[]
  kpts=detector.detect(img)
  kpts,des=descriptor.compute(img,kpts)
  
  test = cv2.drawKeypoints(img, kpts, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
  plt.imshow(test)
  plt.show()

  K.append(kpts)        #se almacena los keypoints en matriz K
  D.append(des)        #se almacena los descriptores en matriz D

  visual_words=np.zeros((len(D),k),dtype=np.float32)
  for i in range(len(D)):
    words,distance=vq.vq(D[i],CB)       #a que centroide CB pertenece cada descriptor D(característica)
    visual_words[i,:]=np.bincount(words,minlength=k)

  #Metiendo la representación de la imagen en la base de datos(modelo), al tratarse de una imagen, res tiene un solo dato
  print(visual_words)
  print(scaler.transform(visual_words))
  res = model.predict(scaler.transform(visual_words))
  print(res)

  #Input: representación de la imagen
  #Output: clase a la que pertenece, según el parecido con las clases de la base de datos

  return res[0]

def previous_steps():
  clases_data_base = ['Close_eyes','Open_eyes']
  #Close_eyes: 0
  #Open_eyes: 1
  
  with open('CB_save', 'rb') as fp:
    CB = cPickle.load(fp)

  with open('modelo_save', 'rb') as fp:
    model = cPickle.load(fp)

  with open('scaler_save', 'rb') as fp:
    scaler = cPickle.load(fp)

  
  ## base de datos:
  db = pymysql.connect(host='dbproyecto.chgqdjgci8b3.us-east-1.rds.amazonaws.com', user='admin', password='12345678')

  cursor = db.cursor()
  cursor.execute("select version()")
  data = cursor.fetchone()

  
  # sql = '''drop database  proyecto_cognitive'''
  # cursor.execute(sql)
  # sql = '''create database proyecto_cognitive'''
  # cursor.execute(sql)
  sql = '''use proyecto_cognitive'''
  cursor.execute(sql)
  cursor.connection.commit()

  # sql = '''
  # create table incidencias (
  # id_incidencia int primary key auto_increment,
	# latitud float(10) not null,
	# longitud float(10) not null,
	# nombre varchar(20) not null,
	# apellido varchar(20) not null,
	# hora_infraccion varchar(20) not null,
	# placa_camion varchar(7) not null
  # ); '''
  # cursor.execute(sql)

  # sql = '''
  # create table conductores (
  # id_conductor int primary key auto_increment,
	# nombre varchar(20) not null,
	# apellido varchar(20) not null,
	# edad int not null,
	# cantidad_incidencias int not null,
	# estatus_conductor int not null,
  # placa_camion varchar(7) not null,
	# nombre_central varchar(20) not null
  # ); '''
  # cursor.execute(sql)


  ## temporal
  # sql = '''insert into conductores(nombre,apellido,edad,cantidad_incidencias,estatus_conductor,placa_camion,nombre_central) values('%s', '%s', '%s','%s', '%s', '%s','%s')''' % ('hans','rodriguez',100,5,1,'12LD5','Primax')
  # cursor.execute(sql)
  ##

  return CB, model, scaler, clases_data_base, cursor, db

CB, model, scaler, clases_data_base, cursor, db = previous_steps()
alerta_close_eyes = 0
id = 2
video_stream()
# label for video
label_html = 'Capturing...'
# initialze bounding box to empty
bbox = ''
count = 0 
while True:
    js_reply = video_frame(label_html, bbox)
    # if not js_reply:
    #     break
    img = js_to_image(js_reply["img"])
    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

    img = cv2.resize(img, (800,480))

    img = mask(img)

    predicted_value = prediction(img, CB, k=10)
    #contador = contador + 1

    # 1seg = 6frames
    if (predicted_value == 1):
      alerta_close_eyes = 0
    else:
      alerta_close_eyes = alerta_close_eyes + 1
      if (alerta_close_eyes >= 3):             #2 seconds sleeping and Alert
        display(Audio("alerta.wav", autoplay=True))

        ###
        #mandar data para la incidencia:
        latitud, longitud, hora_infraccion = obtencion_data_incidencias()
        latitud = float(latitud)
        longitud = float(longitud)

        sentence = f"select nombre from conductores where id_conductor = '{id}';"
        cursor.execute(sentence)
        #print(cursor.fetchone()[0])
        nombre = cursor.fetchone()[0]
        #print(nombre)

        sentence = f"select apellido from conductores where id_conductor = '{id}';"
        cursor.execute(sentence)
        apellido = cursor.fetchone()[0]

        sentence = f"select placa_camion from conductores where id_conductor = '{id}';"
        cursor.execute(sentence)
        placa_camion = cursor.fetchone()[0]

        sql = '''insert into incidencias(latitud,longitud,nombre,apellido,hora_infraccion,placa_camion) values('%s', '%s', '%s','%s', '%s', '%s')''' % (latitud,longitud,nombre,apellido,hora_infraccion,placa_camion)
        #print(latitud);print(longitud);print(nombre);print(apellido);print(hora_infraccion);print(placa_camion)
        #print(type(latitud));print(type(longitud));print(type(nombre));print(type(apellido));print(type(hora_infraccion));print(type(placa_camion))
        cursor.execute(sql)
        db.commit()
        ###

    print(clases_data_base[predicted_value])

cv2.destroyAllWindows()